apiVersion: v1
kind: Service
metadata:
  name: headless-svc
  namespace: default
spec:
  clusterIP: None
  selector:
    job-name: ptxla-hello-world
---
apiVersion: batch/v1
kind: Job
metadata:
  name: ptxla-hello-world
  namespace: default
spec:
  backoffLimit: 1
  completionMode: Indexed
  completions: 2 # xw32 todo: change to 4
  parallelism: 2 # xw32 todo: change to 4
  template:
    spec:
      containers:
      - args:
        - --num_processes
        - "8"
        - --job_name
        - ptxla-hello-world
        - --sub_domain
        - headless-svc
        - --coordinator_port
        - "1234"
        command:
        - echo
        - $JOB_COMPLETION_INDEX
        image: us-central1-docker.pkg.dev/tpu-pytorch-releases/docker/xla:r2.1.0_3.10_cuda_12.1
        name: ptxla-worker
        ports:
        - containerPort: 1234
        resources:
          limits:
            nvidia.com/gpu: 2
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-v100
      restartPolicy: Never
      subdomain: headless-svc
      tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Exists
